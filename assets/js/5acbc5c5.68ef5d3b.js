"use strict";(globalThis.webpackChunkdazzleduck_website=globalThis.webpackChunkdazzleduck_website||[]).push([[5794],{8453:(e,r,n)=>{n.d(r,{R:()=>t,x:()=>a});var i=n(6540);const l={},s=i.createContext(l);function t(e){const r=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:t(e.components),i.createElement(s.Provider,{value:r},e.children)}},9007:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"connector/dazzleduck-sql-spark/architecture","title":"Architecture","description":"The Spark integration is built as a Spark DataSource V2 that communicates with DazzleDuck SQL Server using Arrow Flight SQL.","source":"@site/docs/connector/dazzleduck-sql-spark/architecture.md","sourceDirName":"connector/dazzleduck-sql-spark","slug":"/connector/dazzleduck-sql-spark/architecture","permalink":"/dazzleduck-website/docs/connector/dazzleduck-sql-spark/architecture","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_label":"Architecture","sidebar_position":2},"sidebar":"docSidebar","previous":{"title":"Installation","permalink":"/dazzleduck-website/docs/connector/dazzleduck-sql-spark/installation"},"next":{"title":"Usage","permalink":"/dazzleduck-website/docs/connector/dazzleduck-sql-spark/usage"}}');var l=n(4848),s=n(8453);const t={sidebar_label:"Architecture",sidebar_position:2},a="Architecture",c={},o=[{value:"Key Components",id:"key-components",level:2},{value:"ArrowRPCTableProvider",id:"arrowrpctableprovider",level:3},{value:"ArrowRPCTable",id:"arrowrpctable",level:3},{value:"ArrowRPCScan / ArrowRPCScanBuilder",id:"arrowrpcscan--arrowrpcscanbuilder",level:3},{value:"ArrowPartitionReaderFactory",id:"arrowpartitionreaderfactory",level:3},{value:"FlightSqlClientPool",id:"flightsqlclientpool",level:3},{value:"Query Lifecycle",id:"query-lifecycle",level:2},{value:"Query Rewriting",id:"query-rewriting",level:2},{value:"Partition Awareness",id:"partition-awareness",level:2},{value:"Security Model",id:"security-model",level:2}];function d(e){const r={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(r.header,{children:(0,l.jsx)(r.h1,{id:"architecture",children:"Architecture"})}),"\n",(0,l.jsxs)(r.p,{children:["The Spark integration is built as a ",(0,l.jsx)(r.strong,{children:"Spark DataSource V2"})," that communicates with DazzleDuck SQL Server using ",(0,l.jsx)(r.strong,{children:"Arrow Flight SQL"}),"."]}),"\n",(0,l.jsx)(r.hr,{}),"\n",(0,l.jsx)(r.h2,{id:"key-components",children:"Key Components"}),"\n",(0,l.jsx)(r.h3,{id:"arrowrpctableprovider",children:"ArrowRPCTableProvider"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsxs)(r.li,{children:["Entry point used by Spark (",(0,l.jsx)(r.code,{children:"USING io.dazzleduck.sql.spark.ArrowRPCTableProvider"}),")"]}),"\n",(0,l.jsx)(r.li,{children:"Parses Spark OPTIONS"}),"\n",(0,l.jsx)(r.li,{children:"Constructs Arrow RPC\u2013backed tables"}),"\n"]}),"\n",(0,l.jsx)(r.h3,{id:"arrowrpctable",children:"ArrowRPCTable"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Represents a logical Spark table"}),"\n",(0,l.jsx)(r.li,{children:"Exposes schema and partitioning information"}),"\n",(0,l.jsx)(r.li,{children:"Delegates scanning to Arrow RPC readers"}),"\n"]}),"\n",(0,l.jsx)(r.h3,{id:"arrowrpcscan--arrowrpcscanbuilder",children:"ArrowRPCScan / ArrowRPCScanBuilder"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Converts Spark logical plans into Arrow Flight SQL queries"}),"\n",(0,l.jsx)(r.li,{children:"Handles projection, filtering, and aggregation rewriting"}),"\n"]}),"\n",(0,l.jsx)(r.h3,{id:"arrowpartitionreaderfactory",children:"ArrowPartitionReaderFactory"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Creates per-partition readers"}),"\n",(0,l.jsx)(r.li,{children:"Enables Spark parallelism"}),"\n",(0,l.jsx)(r.li,{children:"Each Spark task opens its own Arrow Flight stream"}),"\n"]}),"\n",(0,l.jsx)(r.h3,{id:"flightsqlclientpool",children:"FlightSqlClientPool"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Manages reusable Arrow Flight SQL connections"}),"\n",(0,l.jsx)(r.li,{children:"Handles timeouts and authentication"}),"\n"]}),"\n",(0,l.jsx)(r.hr,{}),"\n",(0,l.jsx)(r.h2,{id:"query-lifecycle",children:"Query Lifecycle"}),"\n",(0,l.jsxs)(r.ol,{children:["\n",(0,l.jsxs)(r.li,{children:["\n",(0,l.jsx)(r.p,{children:"Spark parses SQL query"}),"\n"]}),"\n",(0,l.jsxs)(r.li,{children:["\n",(0,l.jsx)(r.p,{children:"Logical plan is translated into Arrow-compatible SQL"}),"\n"]}),"\n",(0,l.jsxs)(r.li,{children:["\n",(0,l.jsx)(r.p,{children:"Spark requests partitions"}),"\n"]}),"\n",(0,l.jsxs)(r.li,{children:["\n",(0,l.jsx)(r.p,{children:"Each task:"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Opens Arrow Flight SQL connection"}),"\n",(0,l.jsx)(r.li,{children:"Streams Arrow record batches"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(r.li,{children:["\n",(0,l.jsx)(r.p,{children:"Spark consumes batches as internal rows"}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(r.hr,{}),"\n",(0,l.jsx)(r.h2,{id:"query-rewriting",children:"Query Rewriting"}),"\n",(0,l.jsx)(r.p,{children:"The integration rewrites Spark expressions into DuckDB-compatible SQL using:"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:(0,l.jsx)(r.code,{children:"DuckDBExpressionSQLBuilder"})}),"\n",(0,l.jsx)(r.li,{children:(0,l.jsx)(r.code,{children:"QueryBuilderV2"})}),"\n",(0,l.jsx)(r.li,{children:"Expression utilities (literals, field references)"}),"\n"]}),"\n",(0,l.jsx)(r.p,{children:"Unsupported expressions are filtered early to fail fast."}),"\n",(0,l.jsx)(r.hr,{}),"\n",(0,l.jsx)(r.h2,{id:"partition-awareness",children:"Partition Awareness"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Partition columns are declared explicitly"}),"\n",(0,l.jsx)(r.li,{children:"Spark splits work across partitions"}),"\n",(0,l.jsx)(r.li,{children:"DazzleDuck applies partition pruning where possible"}),"\n"]}),"\n",(0,l.jsx)(r.p,{children:"This allows Spark to scale reads efficiently."}),"\n",(0,l.jsx)(r.hr,{}),"\n",(0,l.jsx)(r.h2,{id:"security-model",children:"Security Model"}),"\n",(0,l.jsxs)(r.ul,{children:["\n",(0,l.jsx)(r.li,{children:"Authentication handled via Arrow Flight SQL"}),"\n",(0,l.jsx)(r.li,{children:"Username/password passed via JDBC-style URL"}),"\n",(0,l.jsx)(r.li,{children:"TLS supported when enabled on server"}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,s.R)(),...e.components};return r?(0,l.jsx)(r,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}}}]);